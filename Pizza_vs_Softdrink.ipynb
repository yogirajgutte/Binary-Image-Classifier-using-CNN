{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pizza vs Softdrink.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZWup2jdTDYn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "de5c75c7-4590-4d51-caa6-40677cd13aaa"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KYxkThDVIxQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "764b66cc-8b9a-485b-cbd8-cb751df1f67b"
      },
      "source": [
        "!unzip \"/content/drive/My Drive/Machine Learning/food_classifer_dataset.zip\" -d \"/content/\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/drive/My Drive/Machine Learning/food_classifer_dataset.zip\n",
            "replace /content/classifer_dataset/train/Pizza/pizza1.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace /content/classifer_dataset/train/Pizza/pizza10.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmj3iZfwZgTN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this is going to help in data processing\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3N3z4mkDZzMn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#these libraries are going to help in the model building.\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LI_72cPZ2-8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# dimensions of our images.\n",
        "img_width, img_height = 150, 150\n",
        "\n",
        "#setting up the directories\n",
        "train_data_dir = '/content/classifer_dataset/train'\n",
        "validation_data_dir = '/content/classifer_dataset/validate'\n",
        "\n",
        "#setting up the batchsizes.\n",
        "nb_train_samples = 8400\n",
        "nb_validation_samples = 1600\n",
        "#below are the hyerparameters\n",
        "epochs = 50\n",
        "batch_size = 16"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHVmJMvGaqac",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_shape = (img_width, img_height, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewuQSM0Eb3qq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this is the augmentation configuration we will use for training\n",
        "# augumentation generates more training images by rescaling, shearing, etc\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./ 255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_z-tIyw7doua",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5f52ff71-6e91-4d58-9276-c514fb3bd756"
      },
      "source": [
        "#this generates batches of augment data for training\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 8400 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E45oQgzLeMrv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7e4fd6dd-5257-436a-bc73-ce655d336eeb"
      },
      "source": [
        "# this is the augmentation configuration we will use for validating\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "#this generates batches of augment data for validating\n",
        "validation_generator = val_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1600 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDkT6EwpfiLD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "#for extracting more features, I am adding more number of convolutional layers.\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "#flatten converts the image matrix to a 1-D vector.\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "#below dense function manages the output neuron.\n",
        "model.add(Dense(1, activation='sigmoid'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gH7PIulUnVxU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "outputId": "41c690f2-22d0-4b49-e6bf-3d1d6854384f"
      },
      "source": [
        "#configuring the model\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#to print a summary representation of your model\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_3 (Conv2D)            (None, 148, 148, 32)      896       \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 148, 148, 32)      128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 74, 74, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 74, 74, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 72, 72, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 72, 72, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 36, 36, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 36, 36, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 34, 34, 128)       73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 34, 34, 128)       512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 17, 17, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 17, 17, 128)       0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 36992)             0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 512)               18940416  \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 19,037,121\n",
            "Trainable params: 19,035,649\n",
            "Non-trainable params: 1,472\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXITlx4spiJM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "95823a1d-9613-491d-ac23-f86e0e29d3dc"
      },
      "source": [
        "#model training\n",
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=nb_train_samples // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=nb_validation_samples // batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "525/525 [==============================] - 96s 183ms/step - loss: 0.3969 - accuracy: 0.8436 - val_loss: 0.3918 - val_accuracy: 0.8406\n",
            "Epoch 2/50\n",
            "525/525 [==============================] - 95s 182ms/step - loss: 0.2480 - accuracy: 0.9025 - val_loss: 0.4171 - val_accuracy: 0.8600\n",
            "Epoch 3/50\n",
            "525/525 [==============================] - 95s 181ms/step - loss: 0.2198 - accuracy: 0.9146 - val_loss: 0.1885 - val_accuracy: 0.9212\n",
            "Epoch 4/50\n",
            "525/525 [==============================] - 95s 180ms/step - loss: 0.2051 - accuracy: 0.9233 - val_loss: 0.2640 - val_accuracy: 0.8981\n",
            "Epoch 5/50\n",
            "525/525 [==============================] - 94s 180ms/step - loss: 0.1956 - accuracy: 0.9196 - val_loss: 0.2021 - val_accuracy: 0.9169\n",
            "Epoch 6/50\n",
            "525/525 [==============================] - 95s 181ms/step - loss: 0.1746 - accuracy: 0.9313 - val_loss: 0.1879 - val_accuracy: 0.9337\n",
            "Epoch 7/50\n",
            "525/525 [==============================] - 96s 182ms/step - loss: 0.1833 - accuracy: 0.9304 - val_loss: 0.1799 - val_accuracy: 0.9344\n",
            "Epoch 8/50\n",
            "525/525 [==============================] - 94s 179ms/step - loss: 0.1722 - accuracy: 0.9352 - val_loss: 0.1955 - val_accuracy: 0.9187\n",
            "Epoch 9/50\n",
            "525/525 [==============================] - 94s 179ms/step - loss: 0.1639 - accuracy: 0.9387 - val_loss: 0.2254 - val_accuracy: 0.9019\n",
            "Epoch 10/50\n",
            "525/525 [==============================] - 94s 179ms/step - loss: 0.1530 - accuracy: 0.9427 - val_loss: 0.4062 - val_accuracy: 0.8600\n",
            "Epoch 11/50\n",
            "525/525 [==============================] - 94s 178ms/step - loss: 0.1483 - accuracy: 0.9463 - val_loss: 0.1509 - val_accuracy: 0.9475\n",
            "Epoch 12/50\n",
            "525/525 [==============================] - 93s 178ms/step - loss: 0.1461 - accuracy: 0.9455 - val_loss: 0.5643 - val_accuracy: 0.8525\n",
            "Epoch 13/50\n",
            "525/525 [==============================] - 94s 179ms/step - loss: 0.1429 - accuracy: 0.9494 - val_loss: 0.1506 - val_accuracy: 0.9481\n",
            "Epoch 14/50\n",
            "525/525 [==============================] - 94s 179ms/step - loss: 0.1370 - accuracy: 0.9510 - val_loss: 0.3033 - val_accuracy: 0.8731\n",
            "Epoch 15/50\n",
            "525/525 [==============================] - 94s 179ms/step - loss: 0.1302 - accuracy: 0.9532 - val_loss: 0.1645 - val_accuracy: 0.9394\n",
            "Epoch 16/50\n",
            "525/525 [==============================] - 94s 178ms/step - loss: 0.1297 - accuracy: 0.9558 - val_loss: 0.1477 - val_accuracy: 0.9394\n",
            "Epoch 17/50\n",
            "525/525 [==============================] - 93s 178ms/step - loss: 0.1210 - accuracy: 0.9582 - val_loss: 0.1434 - val_accuracy: 0.9513\n",
            "Epoch 18/50\n",
            "525/525 [==============================] - 96s 182ms/step - loss: 0.1209 - accuracy: 0.9558 - val_loss: 0.1469 - val_accuracy: 0.9394\n",
            "Epoch 19/50\n",
            "525/525 [==============================] - 95s 182ms/step - loss: 0.1138 - accuracy: 0.9587 - val_loss: 0.2017 - val_accuracy: 0.9175\n",
            "Epoch 20/50\n",
            "525/525 [==============================] - 96s 183ms/step - loss: 0.1080 - accuracy: 0.9613 - val_loss: 0.1393 - val_accuracy: 0.9531\n",
            "Epoch 21/50\n",
            "525/525 [==============================] - 96s 183ms/step - loss: 0.1090 - accuracy: 0.9624 - val_loss: 0.1985 - val_accuracy: 0.9319\n",
            "Epoch 22/50\n",
            "525/525 [==============================] - 96s 183ms/step - loss: 0.1040 - accuracy: 0.9677 - val_loss: 0.1319 - val_accuracy: 0.9531\n",
            "Epoch 23/50\n",
            "525/525 [==============================] - 97s 184ms/step - loss: 0.1059 - accuracy: 0.9638 - val_loss: 0.2797 - val_accuracy: 0.9250\n",
            "Epoch 24/50\n",
            "525/525 [==============================] - 97s 184ms/step - loss: 0.0959 - accuracy: 0.9650 - val_loss: 0.1092 - val_accuracy: 0.9613\n",
            "Epoch 25/50\n",
            "525/525 [==============================] - 95s 182ms/step - loss: 0.0972 - accuracy: 0.9657 - val_loss: 0.1098 - val_accuracy: 0.9588\n",
            "Epoch 26/50\n",
            "525/525 [==============================] - 95s 181ms/step - loss: 0.0910 - accuracy: 0.9704 - val_loss: 0.1283 - val_accuracy: 0.9563\n",
            "Epoch 27/50\n",
            "525/525 [==============================] - 95s 180ms/step - loss: 0.0918 - accuracy: 0.9710 - val_loss: 0.3957 - val_accuracy: 0.8169\n",
            "Epoch 28/50\n",
            "525/525 [==============================] - 94s 179ms/step - loss: 0.1014 - accuracy: 0.9661 - val_loss: 0.2059 - val_accuracy: 0.9106\n",
            "Epoch 29/50\n",
            "525/525 [==============================] - 93s 176ms/step - loss: 0.0930 - accuracy: 0.9700 - val_loss: 0.1468 - val_accuracy: 0.9431\n",
            "Epoch 30/50\n",
            "525/525 [==============================] - 93s 176ms/step - loss: 0.0879 - accuracy: 0.9713 - val_loss: 0.1148 - val_accuracy: 0.9544\n",
            "Epoch 31/50\n",
            "525/525 [==============================] - 92s 176ms/step - loss: 0.0891 - accuracy: 0.9714 - val_loss: 0.3316 - val_accuracy: 0.8825\n",
            "Epoch 32/50\n",
            "525/525 [==============================] - 92s 175ms/step - loss: 0.0849 - accuracy: 0.9736 - val_loss: 0.1267 - val_accuracy: 0.9569\n",
            "Epoch 33/50\n",
            "525/525 [==============================] - 93s 177ms/step - loss: 0.0918 - accuracy: 0.9710 - val_loss: 0.3781 - val_accuracy: 0.8550\n",
            "Epoch 34/50\n",
            "525/525 [==============================] - 92s 175ms/step - loss: 0.0999 - accuracy: 0.9665 - val_loss: 0.2508 - val_accuracy: 0.9094\n",
            "Epoch 35/50\n",
            "525/525 [==============================] - 93s 177ms/step - loss: 0.0929 - accuracy: 0.9705 - val_loss: 0.1144 - val_accuracy: 0.9594\n",
            "Epoch 36/50\n",
            "525/525 [==============================] - 94s 179ms/step - loss: 0.0865 - accuracy: 0.9687 - val_loss: 0.1298 - val_accuracy: 0.9619\n",
            "Epoch 37/50\n",
            "525/525 [==============================] - 94s 178ms/step - loss: 0.0892 - accuracy: 0.9740 - val_loss: 0.1230 - val_accuracy: 0.9600\n",
            "Epoch 38/50\n",
            "525/525 [==============================] - 92s 175ms/step - loss: 0.0893 - accuracy: 0.9715 - val_loss: 0.2529 - val_accuracy: 0.9350\n",
            "Epoch 39/50\n",
            "525/525 [==============================] - 91s 173ms/step - loss: 0.0768 - accuracy: 0.9748 - val_loss: 0.1561 - val_accuracy: 0.9406\n",
            "Epoch 40/50\n",
            "525/525 [==============================] - 90s 172ms/step - loss: 0.0774 - accuracy: 0.9756 - val_loss: 0.1720 - val_accuracy: 0.9344\n",
            "Epoch 41/50\n",
            "525/525 [==============================] - 90s 171ms/step - loss: 0.0928 - accuracy: 0.9713 - val_loss: 0.1665 - val_accuracy: 0.9500\n",
            "Epoch 42/50\n",
            "525/525 [==============================] - 90s 171ms/step - loss: 0.0889 - accuracy: 0.9711 - val_loss: 0.1408 - val_accuracy: 0.9481\n",
            "Epoch 43/50\n",
            "525/525 [==============================] - 90s 171ms/step - loss: 0.0841 - accuracy: 0.9756 - val_loss: 0.3526 - val_accuracy: 0.9525\n",
            "Epoch 44/50\n",
            "525/525 [==============================] - 90s 172ms/step - loss: 0.0737 - accuracy: 0.9763 - val_loss: 0.2016 - val_accuracy: 0.9494\n",
            "Epoch 45/50\n",
            "525/525 [==============================] - 90s 171ms/step - loss: 0.0805 - accuracy: 0.9742 - val_loss: 0.1310 - val_accuracy: 0.9519\n",
            "Epoch 46/50\n",
            "525/525 [==============================] - 90s 171ms/step - loss: 0.0755 - accuracy: 0.9750 - val_loss: 0.1799 - val_accuracy: 0.9237\n",
            "Epoch 47/50\n",
            "525/525 [==============================] - 90s 172ms/step - loss: 0.0816 - accuracy: 0.9735 - val_loss: 0.1744 - val_accuracy: 0.9262\n",
            "Epoch 48/50\n",
            "525/525 [==============================] - 89s 170ms/step - loss: 0.0739 - accuracy: 0.9745 - val_loss: 0.1038 - val_accuracy: 0.9631\n",
            "Epoch 49/50\n",
            "525/525 [==============================] - 88s 168ms/step - loss: 0.0786 - accuracy: 0.9782 - val_loss: 0.1943 - val_accuracy: 0.9400\n",
            "Epoch 50/50\n",
            "525/525 [==============================] - 88s 168ms/step - loss: 0.0738 - accuracy: 0.9760 - val_loss: 0.1807 - val_accuracy: 0.9444\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3210176dd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nU3iYT9hEbkU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#to save the weights in the model as a HDFS file\n",
        "\n",
        "model.save_weights('model_weight.h5')\n",
        "\n",
        "#to save the architecture of the model as a json file\n",
        "\n",
        "with open('model_architecture.json','w') as f:\n",
        "    f.write(model.to_json())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqsecluDElwk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "from keras.models import model_from_json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3ZH2EbBEx-P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model reconstruction from JSON file\n",
        "with open('/content/food_model_architecture.json', 'r') as f:\n",
        "    model = model_from_json(f.read())\n",
        "\n",
        "# Load weights into the new model\n",
        "model.load_weights('/content/first_try.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4GOYHzkE2Qs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "test_image=image.load_img('/content/images (1).jfif',target_size=(img_width,img_height))\n",
        "test_image=image.img_to_array(test_image)\n",
        "test_image=np.expand_dims(test_image,axis=0)\n",
        "result=model.predict(test_image)\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TS8yKgpE3c9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if result[0][0]==1.0:\n",
        "    prediction='SoftDrink'\n",
        "else:\n",
        "    prediction='Pizza'\n",
        "print(\"You got a \"+ prediction + \" Yupeeeeeeeeeeeeeeeeeeeeeeeeeeeeee!!!\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}